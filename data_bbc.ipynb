{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033a2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f045cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "   ArticleId                                               Text  Category\n",
      "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
      "1        154  german business confidence slides german busin...  business\n",
      "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
      "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
      "4        917  enron bosses in $168m payout eighteen former e...  business\n",
      "Test Dataset:\n",
      "   ArticleId                                               Text\n",
      "0       1018  qpr keeper day heads for preston queens park r...\n",
      "1       1319  software watching while you work software that...\n",
      "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
      "3        459  india s reliance family feud heats up the ongo...\n",
      "4       1020  boro suffer morrison injury blow middlesbrough...\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset\n",
    "train_df = pd.read_csv(\"C:\\\\Users\\\\nizar\\\\NLP_projet_Nizar_el_Mouaquit\\\\NLP_project\\\\BBC News Train.csv\")\n",
    "# Load test dataset\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\nizar\\\\NLP_projet_Nizar_el_Mouaquit\\\\NLP_project\\\\BBC News Test.csv\")\n",
    "# Print first rows of the train dataset\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "# Print first rows of the test dataset\n",
    "print(\"Test Dataset:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9254ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ArticleId                                               Text  \\\n",
      "0          1833  worldcom ex-boss launches defence lawyers defe...   \n",
      "1           154  german business confidence slides german busin...   \n",
      "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
      "3          1976  lifestyle  governs mobile choice  faster  bett...   \n",
      "4           917  enron bosses in $168m payout eighteen former e...   \n",
      "...         ...                                                ...   \n",
      "1485        857  double eviction from big brother model caprice...   \n",
      "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
      "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
      "1488       1587  apple ipod family expands market apple has exp...   \n",
      "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
      "\n",
      "           Category  \n",
      "0          business  \n",
      "1          business  \n",
      "2          business  \n",
      "3              tech  \n",
      "4          business  \n",
      "...             ...  \n",
      "1485  entertainment  \n",
      "1486  entertainment  \n",
      "1487       business  \n",
      "1488           tech  \n",
      "1489           tech  \n",
      "\n",
      "[1490 rows x 3 columns]\n",
      "Pre-processed Train Dataset:\n",
      "      ArticleId                                               Text  \\\n",
      "0          1833  worldcom exboss launches defence lawyers defen...   \n",
      "1           154  german business confidence slides german busin...   \n",
      "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
      "3          1976  lifestyle governs mobile choice faster better ...   \n",
      "4           917  enron bosses in m payout eighteen former enron...   \n",
      "...         ...                                                ...   \n",
      "1485        857  double eviction from big brother model caprice...   \n",
      "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
      "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
      "1488       1587  apple ipod family expands market apple has exp...   \n",
      "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
      "\n",
      "           Category  \n",
      "0          business  \n",
      "1          business  \n",
      "2          business  \n",
      "3              tech  \n",
      "4          business  \n",
      "...             ...  \n",
      "1485  entertainment  \n",
      "1486  entertainment  \n",
      "1487       business  \n",
      "1488           tech  \n",
      "1489           tech  \n",
      "\n",
      "[1490 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation marks\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Add specific chosen patterns/sentences\n",
    "    irrelevant_patterns = [\n",
    "        r'\\birrelevant_word\\b',\n",
    "        r'\\bunwanted_sentence\\b'\n",
    "    ]\n",
    "    for pattern in irrelevant_patterns:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    # Remove whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Load the train dataset from CSV file\n",
    "train_df = pd.read_csv(\"C:\\\\Users\\\\nizar\\\\NLP_projet_Nizar_el_Mouaquit\\\\NLP_project\\\\BBC News Train.csv\")\n",
    "print(train_df)\n",
    "# Apply text preprocessing on the 'text' column\n",
    "train_df['Text'] = train_df['Text'].apply(preprocess_text)\n",
    "# Print first rows preprocessed dataset\n",
    "print(\"Pre-processed Train Dataset:\")\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4224234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform case :\n",
      "      ArticleId                                               Text  \\\n",
      "0          1833  worldcom exboss launches defence lawyers defen...   \n",
      "1           154  german business confidence slides german busin...   \n",
      "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
      "3          1976  lifestyle governs mobile choice faster better ...   \n",
      "4           917  enron bosses in m payout eighteen former enron...   \n",
      "...         ...                                                ...   \n",
      "1485        857  double eviction from big brother model caprice...   \n",
      "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
      "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
      "1488       1587  apple ipod family expands market apple has exp...   \n",
      "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
      "\n",
      "           Category  \n",
      "0          business  \n",
      "1          business  \n",
      "2          business  \n",
      "3              tech  \n",
      "4          business  \n",
      "...             ...  \n",
      "1485  entertainment  \n",
      "1486  entertainment  \n",
      "1487       business  \n",
      "1488           tech  \n",
      "1489           tech  \n",
      "\n",
      "[1490 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def Transform_case(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "train_df['Text'] = train_df['Text'].apply(Transform_case)\n",
    "# Print first rows of the preprocessed data\n",
    "print(\"Transform case :\")\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f832e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nizar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nizar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ArticleId                                               Text  \\\n",
      "0          1833  worldcom exboss launches defence lawyers defen...   \n",
      "1           154  german business confidence slides german busin...   \n",
      "2          1101  bbc poll indicates economic gloom citizens maj...   \n",
      "3          1976  lifestyle governs mobile choice faster better ...   \n",
      "4           917  enron bosses payout eighteen former enron dire...   \n",
      "...         ...                                                ...   \n",
      "1485        857  double eviction big brother model caprice holb...   \n",
      "1486        325  dj double act revamp chart show dj duo jk joel...   \n",
      "1487       1590  weak dollar hits reuters revenues media group ...   \n",
      "1488       1587  apple ipod family expands market apple expande...   \n",
      "1489        538  santy worm makes unwelcome visit thousands web...   \n",
      "\n",
      "           Category  \n",
      "0          business  \n",
      "1          business  \n",
      "2          business  \n",
      "3              tech  \n",
      "4          business  \n",
      "...             ...  \n",
      "1485  entertainment  \n",
      "1486  entertainment  \n",
      "1487       business  \n",
      "1488           tech  \n",
      "1489           tech  \n",
      "\n",
      "[1490 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in tokens if word.casefold() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "train_df['Text'] = train_df['Text'].apply(remove_stopwords)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de35807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ArticleId                                               Text  \\\n",
      "0          1833  [worldcom, exboss, launches, defence, lawyers,...   \n",
      "1           154  [german, business, confidence, slides, german,...   \n",
      "2          1101  [bbc, poll, indicates, economic, gloom, citize...   \n",
      "3          1976  [lifestyle, governs, mobile, choice, faster, b...   \n",
      "4           917  [enron, bosses, payout, eighteen, former, enro...   \n",
      "...         ...                                                ...   \n",
      "1485        857  [double, eviction, big, brother, model, capric...   \n",
      "1486        325  [dj, double, act, revamp, chart, show, dj, duo...   \n",
      "1487       1590  [weak, dollar, hits, reuters, revenues, media,...   \n",
      "1488       1587  [apple, ipod, family, expands, market, apple, ...   \n",
      "1489        538  [santy, worm, makes, unwelcome, visit, thousan...   \n",
      "\n",
      "           Category  \n",
      "0          business  \n",
      "1          business  \n",
      "2          business  \n",
      "3              tech  \n",
      "4          business  \n",
      "...             ...  \n",
      "1485  entertainment  \n",
      "1486  entertainment  \n",
      "1487       business  \n",
      "1488           tech  \n",
      "1489           tech  \n",
      "\n",
      "[1490 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "# example\n",
    "train_df['Text'] = train_df['Text'].apply(tokenize_text)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4aeeee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF features: (1490, 25213)\n",
      "Feature names (vocabulary):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Print the feature names(vocabulary)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names (vocabulary):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "#list to strings\n",
    "train_df['Text'] = train_df['Text'].apply(lambda x: ' '.join(x))\n",
    "# Extract preprocessed text\n",
    "text_data = train_df['Text'].values\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit/transform the text data into TF-IDF features\n",
    "tfidf_features = vectorizer.fit_transform(text_data)\n",
    "# Print the shape of the TF-IDF features\n",
    "print(\"Shape of TF-IDF features:\", tfidf_features.shape)\n",
    "# Print the feature names(vocabulary)\n",
    "print(\"Feature names (vocabulary):\")\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f448536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.90      0.99      0.94        75\n",
      "entertainment       0.96      0.98      0.97        46\n",
      "     politics       0.98      0.93      0.95        56\n",
      "        sport       0.98      1.00      0.99        63\n",
      "         tech       1.00      0.90      0.95        58\n",
      "\n",
      "     accuracy                           0.96       298\n",
      "    macro avg       0.97      0.96      0.96       298\n",
      " weighted avg       0.96      0.96      0.96       298\n",
      "\n",
      "Accuracy: 0.959731543624161\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.90      0.99      0.94        75\n",
      "entertainment       0.96      0.98      0.97        46\n",
      "     politics       0.98      0.93      0.95        56\n",
      "        sport       0.98      1.00      0.99        63\n",
      "         tech       1.00      0.90      0.95        58\n",
      "\n",
      "     accuracy                           0.96       298\n",
      "    macro avg       0.97      0.96      0.96       298\n",
      " weighted avg       0.96      0.96      0.96       298\n",
      "\n",
      "Accuracy: 0.959731543624161\n"
     ]
    }
   ],
   "source": [
    "# Extraction reprocessed text and corresponding labels\n",
    "text_data = train_df['Text'].values\n",
    "labels = train_df['Category'].values\n",
    "# Data Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.2, random_state=42)\n",
    "# Create an instance of NuSVC classifier\n",
    "svm_classifier = NuSVC(kernel='rbf')\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "# Predict the labels for test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "text_data = train_df['Text'].values\n",
    "labels = train_df['Category'].values\n",
    "# instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit/transform the text data into TF-IDF features\n",
    "tfidf_features = vectorizer.fit_transform(text_data)\n",
    "# Split data to training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.2, random_state=42)\n",
    "# Create instance of NuSVC classifier\n",
    "svm_classifier = NuSVC(kernel='rbf')\n",
    "# Train SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "# Predict labels test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "# Evaluate the performance of the classifier\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3ff6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\n",
      "0      qpr keeper day heads for preston queens park r...\n",
      "1      software watching while you work software that...\n",
      "2      d arcy injury adds to ireland woe gordon d arc...\n",
      "3      india s reliance family feud heats up the ongo...\n",
      "4      boro suffer morrison injury blow middlesbrough...\n",
      "                             ...                        \n",
      "730    eu to probe alitalia state aid the european co...\n",
      "731    u2 to play at grammy awards show irish rock ba...\n",
      "732    sport betting rules in spotlight a group of mp...\n",
      "733    alfa romeos to get gm engines fiat is to stop ...\n",
      "734    citizenship event for 18s touted citizenship c...\n",
      "Name: Text, Length: 735, dtype: object\n",
      "Test Predictions:\n",
      "['sport' 'tech' 'sport' 'business' 'sport' 'sport' 'politics' 'politics'\n",
      " 'entertainment' 'business' 'business' 'tech' 'politics' 'tech'\n",
      " 'entertainment' 'sport' 'politics' 'tech' 'entertainment' 'entertainment'\n",
      " 'business' 'politics' 'sport' 'business' 'politics' 'sport' 'business'\n",
      " 'sport' 'sport' 'business' 'politics' 'tech' 'business' 'business'\n",
      " 'sport' 'sport' 'sport' 'business' 'entertainment' 'entertainment' 'tech'\n",
      " 'politics' 'entertainment' 'tech' 'sport' 'tech' 'entertainment'\n",
      " 'business' 'politics' 'business' 'politics' 'business' 'business'\n",
      " 'business' 'tech' 'politics' 'tech' 'entertainment' 'sport' 'tech'\n",
      " 'sport' 'entertainment' 'tech' 'politics' 'business' 'entertainment'\n",
      " 'sport' 'tech' 'sport' 'sport' 'business' 'sport' 'business' 'politics'\n",
      " 'tech' 'sport' 'tech' 'tech' 'tech' 'entertainment' 'politics' 'sport'\n",
      " 'entertainment' 'entertainment' 'business' 'entertainment' 'business'\n",
      " 'entertainment' 'business' 'tech' 'business' 'politics' 'sport' 'tech'\n",
      " 'sport' 'sport' 'sport' 'sport' 'sport' 'sport' 'politics' 'sport'\n",
      " 'politics' 'entertainment' 'business' 'sport' 'politics' 'sport'\n",
      " 'politics' 'entertainment' 'sport' 'business' 'entertainment' 'sport'\n",
      " 'politics' 'sport' 'politics' 'sport' 'politics' 'business'\n",
      " 'entertainment' 'business' 'entertainment' 'entertainment' 'tech' 'sport'\n",
      " 'business' 'entertainment' 'business' 'entertainment' 'business'\n",
      " 'politics' 'politics' 'tech' 'business' 'business' 'politics' 'tech'\n",
      " 'entertainment' 'sport' 'business' 'tech' 'sport' 'entertainment'\n",
      " 'politics' 'sport' 'sport' 'entertainment' 'entertainment' 'tech'\n",
      " 'business' 'tech' 'politics' 'entertainment' 'sport' 'sport' 'sport'\n",
      " 'sport' 'entertainment' 'tech' 'business' 'tech' 'business' 'tech'\n",
      " 'business' 'tech' 'entertainment' 'tech' 'tech' 'politics' 'business'\n",
      " 'politics' 'business' 'business' 'entertainment' 'politics' 'tech'\n",
      " 'business' 'business' 'tech' 'sport' 'politics' 'sport' 'politics' 'tech'\n",
      " 'entertainment' 'politics' 'business' 'politics' 'entertainment'\n",
      " 'politics' 'business' 'entertainment' 'sport' 'tech' 'tech' 'business'\n",
      " 'tech' 'politics' 'business' 'sport' 'politics' 'business'\n",
      " 'entertainment' 'business' 'business' 'sport' 'tech' 'business' 'sport'\n",
      " 'entertainment' 'entertainment' 'sport' 'entertainment' 'sport' 'tech'\n",
      " 'business' 'entertainment' 'sport' 'entertainment' 'sport'\n",
      " 'entertainment' 'politics' 'business' 'tech' 'entertainment' 'business'\n",
      " 'politics' 'business' 'tech' 'business' 'sport' 'politics' 'politics'\n",
      " 'politics' 'politics' 'sport' 'business' 'entertainment' 'politics'\n",
      " 'sport' 'politics' 'business' 'sport' 'tech' 'business' 'politics'\n",
      " 'business' 'politics' 'business' 'business' 'sport' 'tech' 'politics'\n",
      " 'entertainment' 'tech' 'entertainment' 'tech' 'sport' 'sport' 'tech'\n",
      " 'sport' 'sport' 'sport' 'entertainment' 'sport' 'politics' 'tech'\n",
      " 'business' 'sport' 'business' 'sport' 'business' 'sport' 'entertainment'\n",
      " 'business' 'business' 'entertainment' 'politics' 'business' 'sport'\n",
      " 'sport' 'tech' 'sport' 'sport' 'entertainment' 'business' 'sport' 'tech'\n",
      " 'politics' 'entertainment' 'business' 'business' 'politics' 'sport'\n",
      " 'entertainment' 'politics' 'business' 'sport' 'sport' 'tech'\n",
      " 'entertainment' 'sport' 'business' 'tech' 'business' 'sport' 'politics'\n",
      " 'politics' 'entertainment' 'politics' 'entertainment' 'politics'\n",
      " 'business' 'politics' 'tech' 'business' 'sport' 'tech' 'entertainment'\n",
      " 'politics' 'sport' 'politics' 'politics' 'tech' 'politics' 'sport' 'tech'\n",
      " 'politics' 'tech' 'tech' 'entertainment' 'business' 'tech' 'politics'\n",
      " 'business' 'politics' 'sport' 'tech' 'entertainment' 'entertainment'\n",
      " 'business' 'sport' 'tech' 'tech' 'entertainment' 'tech' 'business'\n",
      " 'sport' 'entertainment' 'tech' 'business' 'politics' 'tech' 'tech'\n",
      " 'politics' 'politics' 'sport' 'business' 'tech' 'sport' 'politics'\n",
      " 'politics' 'business' 'tech' 'sport' 'politics' 'business' 'politics'\n",
      " 'politics' 'tech' 'entertainment' 'business' 'business' 'sport' 'sport'\n",
      " 'sport' 'tech' 'sport' 'politics' 'tech' 'tech' 'politics' 'business'\n",
      " 'sport' 'sport' 'entertainment' 'entertainment' 'sport' 'tech' 'tech'\n",
      " 'sport' 'tech' 'entertainment' 'politics' 'tech' 'sport' 'business'\n",
      " 'politics' 'entertainment' 'business' 'tech' 'sport' 'politics'\n",
      " 'business' 'business' 'politics' 'tech' 'sport' 'entertainment'\n",
      " 'business' 'tech' 'business' 'tech' 'sport' 'sport' 'politics' 'business'\n",
      " 'tech' 'sport' 'politics' 'business' 'tech' 'tech' 'politics' 'tech'\n",
      " 'business' 'sport' 'business' 'entertainment' 'business' 'entertainment'\n",
      " 'politics' 'entertainment' 'sport' 'business' 'business' 'business'\n",
      " 'sport' 'entertainment' 'business' 'entertainment' 'entertainment'\n",
      " 'sport' 'tech' 'entertainment' 'entertainment' 'business' 'politics'\n",
      " 'entertainment' 'politics' 'politics' 'sport' 'business' 'sport'\n",
      " 'politics' 'entertainment' 'entertainment' 'business' 'business' 'sport'\n",
      " 'politics' 'sport' 'business' 'politics' 'business' 'sport' 'sport'\n",
      " 'politics' 'sport' 'tech' 'business' 'business' 'sport' 'politics' 'tech'\n",
      " 'business' 'politics' 'tech' 'politics' 'politics' 'entertainment' 'tech'\n",
      " 'sport' 'sport' 'politics' 'business' 'tech' 'politics' 'sport' 'sport'\n",
      " 'entertainment' 'business' 'entertainment' 'entertainment' 'business'\n",
      " 'politics' 'sport' 'business' 'tech' 'tech' 'business' 'politics' 'sport'\n",
      " 'business' 'sport' 'business' 'politics' 'business' 'sport' 'politics'\n",
      " 'business' 'sport' 'politics' 'business' 'tech' 'politics' 'sport'\n",
      " 'politics' 'entertainment' 'sport' 'politics' 'business' 'business'\n",
      " 'business' 'tech' 'politics' 'politics' 'sport' 'business' 'tech' 'tech'\n",
      " 'tech' 'sport' 'tech' 'politics' 'business' 'business' 'sport'\n",
      " 'entertainment' 'politics' 'business' 'tech' 'tech' 'sport' 'tech'\n",
      " 'business' 'sport' 'business' 'business' 'business' 'politics' 'politics'\n",
      " 'entertainment' 'entertainment' 'entertainment' 'politics' 'tech' 'tech'\n",
      " 'politics' 'entertainment' 'business' 'sport' 'sport' 'politics'\n",
      " 'entertainment' 'politics' 'sport' 'business' 'business' 'business'\n",
      " 'entertainment' 'tech' 'sport' 'business' 'politics' 'politics' 'tech'\n",
      " 'politics' 'sport' 'politics' 'business' 'tech' 'business' 'sport'\n",
      " 'sport' 'tech' 'sport' 'entertainment' 'tech' 'entertainment' 'tech'\n",
      " 'sport' 'politics' 'business' 'tech' 'politics' 'entertainment'\n",
      " 'entertainment' 'politics' 'business' 'business' 'tech' 'business'\n",
      " 'business' 'business' 'sport' 'entertainment' 'business' 'sport'\n",
      " 'business' 'sport' 'tech' 'business' 'politics' 'sport' 'business'\n",
      " 'sport' 'sport' 'entertainment' 'politics' 'tech' 'sport' 'business'\n",
      " 'sport' 'business' 'sport' 'sport' 'politics' 'tech' 'business' 'tech'\n",
      " 'business' 'sport' 'tech' 'business' 'entertainment' 'business'\n",
      " 'entertainment' 'sport' 'tech' 'business' 'business' 'business'\n",
      " 'politics' 'sport' 'entertainment' 'tech' 'business' 'sport'\n",
      " 'entertainment' 'business' 'entertainment' 'business' 'politics' 'sport'\n",
      " 'sport' 'business' 'tech' 'sport' 'business' 'business' 'business'\n",
      " 'business' 'business' 'entertainment' 'tech' 'sport' 'politics' 'tech'\n",
      " 'politics' 'tech' 'sport' 'tech' 'entertainment' 'business' 'business'\n",
      " 'entertainment' 'politics' 'sport' 'sport' 'sport' 'entertainment' 'tech'\n",
      " 'politics' 'entertainment' 'sport' 'sport' 'politics' 'tech' 'politics'\n",
      " 'entertainment' 'sport' 'entertainment' 'sport' 'entertainment' 'tech'\n",
      " 'sport' 'sport' 'business' 'tech' 'entertainment' 'business' 'tech'\n",
      " 'business' 'business' 'sport' 'entertainment' 'politics' 'entertainment'\n",
      " 'business' 'politics' 'business' 'politics' 'sport' 'tech' 'tech'\n",
      " 'politics' 'entertainment' 'business' 'tech' 'entertainment'\n",
      " 'entertainment' 'politics' 'business' 'business' 'politics' 'politics'\n",
      " 'tech' 'sport' 'business' 'entertainment' 'business' 'business'\n",
      " 'politics']\n"
     ]
    }
   ],
   "source": [
    "# Extract preprocessed text from test DataFrame\n",
    "test_data = test_df['Text'].apply(preprocess_text)\n",
    "test_data = test_df['Text'].apply(Transform_case)\n",
    "test_data = test_df['Text'].apply(remove_stopwords)\n",
    "test_data = test_df['Text'].apply(tokenize_text)\n",
    "# Join the tokens into strings for each document in the test DataFrame\n",
    "test_data = test_data.apply(lambda tokens: ' '.join(tokens))\n",
    "# Transform the test data into TF-IDF features using the same vectorizer\n",
    "test_tfidf_features = vectorizer.transform(test_data.values)\n",
    "# Predict labels/test data\n",
    "test_pred = svm_classifier.predict(test_tfidf_features)\n",
    "# Print test data/predictions\n",
    "print(\"Test Data:\")\n",
    "print(test_data)\n",
    "print(\"Test Predictions:\")\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308469a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
